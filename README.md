# note
push 
test
gitpod 
27

1. cnn提取特征和vit提取特征的区别
- cnn架构
    - 对纹理/边缘等局部信息特征提取能力好
    - 能够保持空间信息
    - C3-C5从低级的边缘、角点、颜色梯度等特征逐渐过渡到轮廓类别等高级语义特征
- vit架构
    - patch token包含全局上下文,而不是单纯局部纹理, 因此更容易捕捉全局的依赖关系
    - 因为patch的划分可能会丢失细粒度的空间细节, 小目标的检测不如cnn特征, 我这里因为对齐dinov2的前处理用的224, 尝试增大到896,roi_box_head的损失依旧不收敛
    - cnn特征因为保留了空间信息可以直接用来接检测头, dino输出的是[B,N,d]的特征, 这里是将d作为通道数量, N通过reshape后接cnn训练, 应该能够再对齐空间特征

2. backbone冻结/不冻结
- 冻结
    - 能够保留预训练的知识但是拟合能力受限, 适合特定场景的微调, 一开始尝试了coco的训练数据, 想着和dino的训练数据分布应该比较相似, 后来才换成的只有车的数据集
    - 训练占用资源少
- 不冻结
    - 全量训练所有参数拟合能力更强, 新场景数据量不足的情况下容易产生灾难性遗忘, 训练占用资源更多
    - 这里考虑数据量较少, transformer架构本身相比cnn缺少平移不变性和权重共享等归纳偏执, 求解空间更大, 不可能用全量训练, 要是全量训练倒是可以给backbone一个极小的学习率

3. 一阶段和两阶段检测
- 一阶段
    - yolo是直接在输出特征图上做密集预测, 一次性输出目标位置和类别, 相当于目标定位和识别是一起做的
- 两阶段
    - fasterrcnn是先用rpn head 学习正负样本和anchor相对proposal的便宜, 相当于完成了粗略的目标定位, roi head根据proposal提取roi特征完成proposal相对gt的偏移和目标类别, 相当于完成定位的refine和识别
    - frcnn中的anchor匹配默认是与gt的iou > 0.7, yolo中默认是宽或者高是上下四倍的关系, yolo的策略更为宽松能为一个目标分配更多的anchor, frcnn实际是做了两次目标框的定位, 所以是不是应该放松anchor匹配的限制试试? 毕竟能拟合两次 
    
一开始anchor设置不合理, 每个目标平均分配3~5个anchor, 后来做了聚类每个目标能分配四五十个,确实能够定位到一些比较大的目标了, 所以感觉还是输入分辨率低加上vit本身会损失空间信息, 应该尝试大分辨率, 后边计划先看一下dinov3在这个数据集上特征可视化的结果确保提的特征没有问题, 还是采用冻结backbone的方案, FPN这里使用的最后一层的输出特征上采样作为C3和C4, 应该尝试从中间取特征? 看一下别的vit做检测的fpn是怎么做的, 应该打印看一下rpn的proposal正样本是不是有问题, roi_box_reg_loss一直不收敛可能是上个阶段的proposal的质量就不行


